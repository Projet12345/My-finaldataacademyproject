{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95f7836",
   "metadata": {},
   "source": [
    "## Data Afrique Hub Project\n",
    "This notebook is used to create a model for analysing the sentiments of film commentaries. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb3e6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 11:18:47.133610: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-06 11:18:47.133653: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-06 11:19:16.703670: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-06 11:19:16.704007: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-06 11:19:16.704036: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[nltk_data] Downloading package punkt to /home/anderson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense,Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve,confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011cb764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sentiment\n",
      "count  50000.000000\n",
      "mean       0.500000\n",
      "std        0.500005\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.500000\n",
      "75%        1.000000\n",
      "max        1.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      One of the other reviewers has mentioned that ...          1\n",
       "1      A wonderful little production. <br /><br />The...          1\n",
       "2      I thought this was a wonderful way to spend ti...          1\n",
       "3      Basically there's a family where a little boy ...          0\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...          1\n",
       "...                                                  ...        ...\n",
       "49995  I thought this movie did a down right good job...          1\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n",
       "49997  I am a Catholic taught in parochial elementary...          0\n",
       "49998  I'm going to have to disagree with the previou...          0\n",
       "49999  No one expects the Star Trek movies to be high...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file in a pandas DataFrame\n",
    "data = pd.read_csv('../dataset/IMDB_Dataset.csv')\n",
    "sentiment_mapping = {'positive': 1, 'negative': 0} #transforming sentiment into binary\n",
    "data['sentiment'] = data['sentiment'].map(sentiment_mapping)\n",
    "print(data.describe())\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b75868",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e37fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review  sentiment\n",
      "0      One reviewers mentioned watching  Oz episode l...          1\n",
      "1      wonderful little production  filming technique...          1\n",
      "2      thought wonderful way spend time hot summer we...          1\n",
      "3      Basically  family little boy  Jake  thinks  zo...          0\n",
      "4      Petter Mattei   Love Time Money  visually stun...          1\n",
      "...                                                  ...        ...\n",
      "49995  thought movie right good job  nt creative orig...          1\n",
      "49996  Bad plot  bad dialogue  bad acting  idiotic di...          0\n",
      "49997  Catholic taught parochial elementary schools n...          0\n",
      "49998   going disagree previous comment side Maltin o...          0\n",
      "49999  one expects Star Trek movies high art  fans ex...          0\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in tokens if word.lower() not in stop_words]\n",
    "    text = ' '.join(filtered_text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove single letters\n",
    "    text = re.sub(r'\\b\\w\\b', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the reviews\n",
    "data['review'] = data['review'].apply(preprocess_text)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36a78b",
   "metadata": {},
   "source": [
    "## Subdivision of data into training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d021d078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fault actors  put great performances   overall story well executed  movie opens great zinger  crazy old guy forces young Aborigine girl  car road   re forced endure 40 minutes character development entirely new group characters  nt know 40 minutes  turns ones eventually discover girl  body  story progresses thereWhile story pick point  really goes nowhere   hours  asked  point  see characters struggle accusations racism stupidity handled discovery  story ultimately unsatisfying felt unfinished  well acted   strong enough backbone film warrant recommending '\n",
      " 'first thing thought saw films  really film  least imagine spontaneously hear word  film   entirely symbolic  everything figurative meaning  used express thing symbolic way  find strange  acquainted philosophy  religion  spiritual life  think  fairytale  even weird one  chaotic   legend Zu  perfectly transparent  like  tells us images story fight light darkness  fight old humanity  every one search sens life confronted  film obviously made Buddhists  Buddhist  religion vision world human different  far humans human nature necessarily common experiences understand  really beautiful film  films like  films meaning  many empty stories good make time pass quickly '\n",
      " 'Postfeminist depiction cruelty sadismSpoiler alert  underrated gem film tells story Flavia  Fifteenth Century girl Noble birth walled convent defining father indeed whole Medieval Christian society viewing fallen Islamic warrior human rather demonic figureUnable accept patriarchal rule convent  explicitly stated scene Bishop arrives flanked soldiers monks  Flavia begins explicitly question society finds  butting whole system subjugation  repression violence  inevitably brings tragic end around herBilled piece nunsploitation far truth  film depiction consequences violence  effects patriarchal dominance  nature rebellion corruption human spiritI described title piece postfeminist  end Flavia  triumphs must always corrupted  compromised perverted men  Even Flavia  gruesome end perpetrated men men  women turn away monks look without horrorAs much discussed violence  depiction effects violence horrors world driven mad religious excess  shied away violence would limited film  impact  would cheapened film allowed assimilated within Patriarchal discourse exposing  addition realistic portrait medieval societyBeautifully filmed  brilliantly acted  notably Florinda Bolkin Maria Casares   containing wonderful score piovani still challenging years Flavia classic European Cinema '\n",
      " ...\n",
      " 'saw movie say  drive  days  seems like would great 2nd feature drive 1977  maybe playing one Joan Collins movies    worth watching re feeling nostalgic 70   Silly plot full holes  remind one era made  Interesting see Melanie Griffith young Anne Lockhart quite attractive  though much actress  fact  much acting going movie   sort Dukes Hazzard adventure without twang 1969 Dodge charger jumping stuff Woods  Mecrury Comet jumping garbage dump one '\n",
      " 'Cameron Diaz woman married judge  played Harvey Keitel  whose life fine ex shows things get little complicated  watching movie several times asked  movie ridiculous blah poorly scripted without believability  audience really car happens  Even lovely Cameron ca nt save one scale one ten  '\n",
      " 'good idea use live animals department store window displays      Hare Conditioned  sale Bugs helping promote store manager  Nelson  transferring new department  taxidermy  Naturally  Bugs objects fun beginsusing nearly every department store  children  wear  sports  shoes  costumes  women  nightgowns  nt ask    Bugs comes top every turn  even referring manager  Great GilderSNEEZE   Even trapped confines elevator  Bugs makes best situationDirector Jones top pictorial game always  Blanc  Bugs  natch  Nelson  manager  sound like radio mainstay Gildersleeves  go ask grandparents  And sage word advice  confronted fuzzylooking woman wanting try bathroom slippers  always check earsTen stars  Hare Conditioner   best argument yet animal labor laws ']\n"
     ]
    }
   ],
   "source": [
    "X = data['review'].values\n",
    "y = data['sentiment'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74275e5",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a81ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     2,  6887, 12423],\n",
       "       [    0,     0,     0, ...,     9,  1154,   770],\n",
       "       [  810,  1476,    47, ...,   243,  1773,   326],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  1036,  6698,     4],\n",
       "       [    0,     0,     0, ...,  2289,     4,   579],\n",
       "       [    0,     6,   209, ...,  1533,  5134,  5524]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "max_len = 100  # Define the maximum length of sequences\n",
    "X_train_seq = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_seq = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "X_val_seq = pad_sequences(X_val_seq, maxlen=max_len)\n",
    "X_train_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0532a6d",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27b50cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 11:47:03.861925: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-06 11:47:04.007042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (anderson-HP-ProBook-4540s): /proc/driver/nvidia/version does not exist\n",
      "2024-08-06 11:47:29.880160: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 72816640 exceeds 10% of free system memory.\n",
      "2024-08-06 11:47:30.956931: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 72816640 exceeds 10% of free system memory.\n",
      "2024-08-06 11:47:31.200514: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 72816640 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Creating the sequential model\n",
    "model = Sequential()\n",
    "# Embedding layer:\n",
    "# - input_dim = size of the vocabulary\n",
    "# - output_dim = dimension of the embedding vectors (here 128)\n",
    "# - input_length = maximum length of the input sequences\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n",
    "# LSTM (Long Short-Term Memory) layer:\n",
    "# - 128 units in the LSTM layer\n",
    "# - Captures long-term dependencies in text sequences\n",
    "model.add(LSTM(128))\n",
    "# Fully connected output layer:\n",
    "# - 1 output unit (binary prediction)\n",
    "# - Sigmoid activation to obtain a prediction between 0 and 1\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Dropout regularization layer:\n",
    "# - Dropout rate of 0.3 (30%) to reduce overfitting\n",
    "model.add(Dropout(0.3))\n",
    "# Compiling the model:\n",
    "# - Adam optimizer\n",
    "# - Loss function: Binary Cross-Entropy (for binary prediction)\n",
    "# - Evaluation metric: Accuracy\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8334ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 11:50:56.970694: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 72816640 exceeds 10% of free system memory.\n",
      "2024-08-06 11:50:57.059981: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 72816640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 545s 708ms/step - loss: 2.6446 - accuracy: 0.6688 - val_loss: 0.4885 - val_accuracy: 0.7467\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 383s 766ms/step - loss: 2.4293 - accuracy: 0.7828 - val_loss: 0.4284 - val_accuracy: 0.8375\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "history =model.fit(X_train_seq, y_train, batch_size=64, epochs=2, validation_data=(X_val_seq, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d157e6",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0c75659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 21s 66ms/step\n",
      "Accuracy: 0.8375\n",
      "Precision: 0.9210656142081894\n",
      "Recall: 0.7410200436594563\n",
      "F1 score: 0.8212911030462994\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "# Getting the model predictions on the test data\n",
    "y_pred = model.predict(X_test_seq)\n",
    "y_pred_binary = np.round(y_pred)\n",
    "\n",
    "# Calculating evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "\n",
    "# Displaying the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ecfc5c",
   "metadata": {},
   "source": [
    "## Real test with a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "375ecd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../api/review_model/review_model.h5')\n",
    "with open ('../api/review_model/tokenizer.pkl','wb') as f:\n",
    "    pickle.dump(tokenizer,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03fcdcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "[[0.5366965]]\n",
      "La revue est positive.\n"
     ]
    }
   ],
   "source": [
    "new_review = \"good film\"\n",
    "# Preprocessing the review (ignored in this case)\n",
    "preprocessed_review = new_review\n",
    "# Encoding the review\n",
    "encoded_review = tokenizer.texts_to_sequences([preprocessed_review])\n",
    "# Adjusting the length of the sequence\n",
    "encoded_review = pad_sequences(encoded_review, maxlen=max_len)\n",
    "# Passing the review to the model\n",
    "prediction = model.predict(encoded_review)\n",
    "print(prediction)\n",
    "# Interpreting the prediction\n",
    "if prediction > 0.5:\n",
    "    print(\"The review is positive.\")\n",
    "else:\n",
    "    print(\"The review is negative.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f897a2b",
   "metadata": {},
   "source": [
    "## Plotting important curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d9ddff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extracting training and validation metrics from the history\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Extracting training and validation metrics from the history\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plotting the learning and loss curves on the same figure\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_acc, 'b', label='Training')\n",
    "plt.plot(epochs, val_acc, 'g', label='Validation')\n",
    "plt.title('Learning Curve - Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_loss, 'b', label='Training')\n",
    "plt.plot(epochs, val_loss, 'g', label='Validation')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f9dc1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../api/review/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../api/review/assets\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd248257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97149f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
